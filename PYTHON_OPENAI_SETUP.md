# üêç Python ile ChatGPT API - Development Environment Setup

## üìã ƒ∞√ßindekiler
1. [Gereksinimler](#gereksinimler)
2. [Kurulum Adƒ±mlarƒ±](#kurulum-adƒ±mlarƒ±)
3. [API Key Yapƒ±landƒ±rmasƒ±](#api-key-yapƒ±landƒ±rmasƒ±)
4. [Temel Kullanƒ±m](#temel-kullanƒ±m)
5. [Geli≈ümi≈ü √ñzellikler](#geli≈ümi≈ü-√∂zellikler)
6. [Best Practices](#best-practices)
7. [Troubleshooting](#troubleshooting)

---

## üéØ Gereksinimler

### Sistem Gereksinimleri
- **Python**: 3.7.1 veya √ºzeri
- **pip**: Python package manager
- **OpenAI API Key**: [platform.openai.com](https://platform.openai.com/api-keys)

### ƒ∞≈ületim Sistemi
- ‚úÖ Linux / macOS
- ‚úÖ Windows 10/11
- ‚úÖ WSL (Windows Subsystem for Linux)

---

## üì¶ Kurulum Adƒ±mlarƒ±

### 1. Python Kurulumu Kontrol√º

```bash
# Python versiyonunu kontrol et
python --version
# veya
python3 --version

# pip versiyonunu kontrol et
pip --version
# veya
pip3 --version
```

**Beklenen √áƒ±ktƒ±:**
```
Python 3.11.0
pip 23.0.1
```

### 2. Python Kurulumu (Eƒüer yoksa)

#### üêß Linux (Ubuntu/Debian)
```bash
sudo apt update
sudo apt install python3 python3-pip python3-venv
```

#### üçé macOS
```bash
# Homebrew ile
brew install python3

# veya python.org'dan indir
# https://www.python.org/downloads/macos/
```

#### ü™ü Windows
```powershell
# Microsoft Store'dan Python 3.11 indir
# veya
# https://www.python.org/downloads/windows/

# Kurulum sƒ±rasƒ±nda "Add Python to PATH" se√ßeneƒüini i≈üaretle!
```

---

### 3. Virtual Environment Olu≈üturma

Virtual environment, projenizin baƒüƒ±mlƒ±lƒ±klarƒ±nƒ± izole eder.

```bash
# Proje klas√∂r√º olu≈ütur
mkdir chatgpt-api-project
cd chatgpt-api-project

# Virtual environment olu≈ütur
python3 -m venv venv

# Virtual environment'ƒ± aktifle≈ütir
# Linux/macOS:
source venv/bin/activate

# Windows:
venv\Scripts\activate

# Aktif olduƒüunu g√∂receksiniz:
# (venv) user@computer:~/chatgpt-api-project$
```

---

### 4. OpenAI Python Library Kurulumu

```bash
# OpenAI resmi k√ºt√ºphanesini kur
pip install openai

# Ek yararlƒ± k√ºt√ºphaneler
pip install python-dotenv  # .env dosyasƒ± desteƒüi
pip install requests       # HTTP istekleri
pip install rich           # Terminal output g√ºzelle≈ütirme

# T√ºm baƒüƒ±mlƒ±lƒ±klarƒ± requirements.txt'e kaydet
pip freeze > requirements.txt
```

**requirements.txt √∂rneƒüi:**
```txt
openai==1.12.0
python-dotenv==1.0.0
requests==2.31.0
rich==13.7.0
```

---

## üîë API Key Yapƒ±landƒ±rmasƒ±

### 1. OpenAI API Key Alma

1. [platform.openai.com](https://platform.openai.com/api-keys) adresine git
2. Giri≈ü yap veya hesap olu≈ütur
3. **"Create new secret key"** butonuna tƒ±kla
4. Key'i kopyala (bir daha g√∂remezsin!)
5. G√ºvenli bir yere kaydet

### 2. Environment Variables ile Yapƒ±landƒ±rma (√ñNERƒ∞LEN)

#### Option A: .env Dosyasƒ± (√ñnerilen)

```bash
# Proje klas√∂r√ºnde .env dosyasƒ± olu≈ütur
touch .env

# .env dosyasƒ±nƒ± d√ºzenle
nano .env
```

**.env i√ßeriƒüi:**
```env
# OpenAI API Configuration
OPENAI_API_KEY=sk-your-actual-api-key-here
OPENAI_ORG_ID=org-your-org-id-here  # Opsiyonel

# Model Configuration
OPENAI_MODEL=gpt-4-turbo-preview
OPENAI_MAX_TOKENS=1000
OPENAI_TEMPERATURE=0.7

# Application Settings
DEBUG=True
LOG_LEVEL=INFO
```

**‚ö†Ô∏è G√úVENLƒ∞K UYARISI:**
```bash
# .env dosyasƒ±nƒ± git'e ekleme!
echo ".env" >> .gitignore
echo "venv/" >> .gitignore
echo "__pycache__/" >> .gitignore
echo "*.pyc" >> .gitignore
```

#### Option B: System Environment Variables

**Linux/macOS (.bashrc veya .zshrc):**
```bash
export OPENAI_API_KEY="sk-your-actual-api-key-here"
source ~/.bashrc  # veya ~/.zshrc
```

**Windows (PowerShell):**
```powershell
[System.Environment]::SetEnvironmentVariable('OPENAI_API_KEY', 'sk-your-key', 'User')
```

---

## üöÄ Temel Kullanƒ±m

### 1. Basit Chat Completion

**`basic_example.py`:**
```python
#!/usr/bin/env python3
"""
Basic OpenAI ChatGPT API Example
"""

import os
from openai import OpenAI
from dotenv import load_dotenv

# .env dosyasƒ±nƒ± y√ºkle
load_dotenv()

# OpenAI client'ƒ± ba≈ülat
client = OpenAI(
    api_key=os.getenv('OPENAI_API_KEY')
)

def chat_completion(prompt: str, model: str = "gpt-3.5-turbo") -> str:
    """
    Basit chat completion
    
    Args:
        prompt: Kullanƒ±cƒ± mesajƒ±
        model: OpenAI model ismi
        
    Returns:
        AI'ƒ±n yanƒ±tƒ±
    """
    try:
        response = client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": "Sen yardƒ±mcƒ± bir asistansƒ±n."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7,
            max_tokens=1000
        )
        
        return response.choices[0].message.content
        
    except Exception as e:
        return f"Hata: {str(e)}"

# Kullanƒ±m
if __name__ == "__main__":
    prompt = "Python ile API kullanƒ±mƒ± hakkƒ±nda kƒ±sa bir a√ßƒ±klama yap."
    result = chat_completion(prompt)
    print(result)
```

**√áalƒ±≈ütƒ±rma:**
```bash
python basic_example.py
```

---

### 2. Conversation History ile Chat

**`conversation_example.py`:**
```python
#!/usr/bin/env python3
"""
Conversation History ile ChatGPT API kullanƒ±mƒ±
"""

import os
from openai import OpenAI
from dotenv import load_dotenv
from typing import List, Dict

load_dotenv()
client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))

class ChatBot:
    def __init__(self, system_prompt: str = "Sen yardƒ±mcƒ± bir asistansƒ±n."):
        self.messages: List[Dict[str, str]] = [
            {"role": "system", "content": system_prompt}
        ]
        
    def chat(self, user_message: str, model: str = "gpt-3.5-turbo") -> str:
        """
        Conversation history'yi koruyarak chat yap
        """
        # Kullanƒ±cƒ± mesajƒ±nƒ± ekle
        self.messages.append({"role": "user", "content": user_message})
        
        try:
            # API √ßaƒürƒ±sƒ±
            response = client.chat.completions.create(
                model=model,
                messages=self.messages,
                temperature=0.7,
                max_tokens=1000
            )
            
            # Assistant yanƒ±tƒ±nƒ± al ve kaydet
            assistant_message = response.choices[0].message.content
            self.messages.append({"role": "assistant", "content": assistant_message})
            
            return assistant_message
            
        except Exception as e:
            return f"Hata: {str(e)}"
    
    def clear_history(self):
        """Conversation history'yi temizle (system prompt hari√ß)"""
        self.messages = [self.messages[0]]
    
    def get_history(self) -> List[Dict[str, str]]:
        """Conversation history'yi d√∂nd√ºr"""
        return self.messages[1:]  # System prompt'u atla

# Kullanƒ±m √∂rneƒüi
if __name__ == "__main__":
    bot = ChatBot(system_prompt="Sen Python programlama konusunda uzman bir √∂ƒüretmensin.")
    
    # ƒ∞lk soru
    print("User: Python nedir?")
    response1 = bot.chat("Python nedir?")
    print(f"Bot: {response1}\n")
    
    # Takip sorusu (context korunur)
    print("User: Peki nasƒ±l √∂ƒürenebilirim?")
    response2 = bot.chat("Peki nasƒ±l √∂ƒürenebilirim?")
    print(f"Bot: {response2}\n")
    
    # History'yi g√∂ster
    print("=== Conversation History ===")
    for msg in bot.get_history():
        print(f"{msg['role'].upper()}: {msg['content'][:50]}...")
```

---

### 3. Streaming Responses

**`streaming_example.py`:**
```python
#!/usr/bin/env python3
"""
Streaming API responses - Real-time output
"""

import os
from openai import OpenAI
from dotenv import load_dotenv

load_dotenv()
client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))

def stream_chat(prompt: str, model: str = "gpt-3.5-turbo"):
    """
    Streaming ile yanƒ±t al (kelime kelime)
    """
    try:
        stream = client.chat.completions.create(
            model=model,
            messages=[{"role": "user", "content": prompt}],
            stream=True,  # Streaming aktif!
            temperature=0.7
        )
        
        print("Bot: ", end="", flush=True)
        
        for chunk in stream:
            if chunk.choices[0].delta.content is not None:
                content = chunk.choices[0].delta.content
                print(content, end="", flush=True)
        
        print()  # Yeni satƒ±r
        
    except Exception as e:
        print(f"\nHata: {str(e)}")

# Kullanƒ±m
if __name__ == "__main__":
    prompt = "Yapay zeka nedir? Detaylƒ± a√ßƒ±kla."
    stream_chat(prompt)
```

---

## üé® Geli≈ümi≈ü √ñzellikler

### 1. Retry Logic ve Error Handling

**`advanced_api.py`:**
```python
#!/usr/bin/env python3
"""
Advanced OpenAI API wrapper with retry logic
"""

import os
import time
from typing import Optional, Dict, Any
from openai import OpenAI, OpenAIError, RateLimitError, APIError
from dotenv import load_dotenv

load_dotenv()

class AdvancedChatGPT:
    def __init__(
        self,
        api_key: Optional[str] = None,
        max_retries: int = 3,
        retry_delay: float = 1.0
    ):
        self.client = OpenAI(api_key=api_key or os.getenv('OPENAI_API_KEY'))
        self.max_retries = max_retries
        self.retry_delay = retry_delay
        
    def chat_with_retry(
        self,
        prompt: str,
        model: str = "gpt-3.5-turbo",
        **kwargs
    ) -> Dict[str, Any]:
        """
        Retry logic ile chat completion
        
        Returns:
            {
                'success': bool,
                'content': str,
                'error': Optional[str],
                'usage': dict
            }
        """
        for attempt in range(self.max_retries):
            try:
                response = self.client.chat.completions.create(
                    model=model,
                    messages=[{"role": "user", "content": prompt}],
                    **kwargs
                )
                
                return {
                    'success': True,
                    'content': response.choices[0].message.content,
                    'error': None,
                    'usage': {
                        'prompt_tokens': response.usage.prompt_tokens,
                        'completion_tokens': response.usage.completion_tokens,
                        'total_tokens': response.usage.total_tokens
                    }
                }
                
            except RateLimitError as e:
                # Rate limit - exponential backoff
                wait_time = self.retry_delay * (2 ** attempt)
                print(f"‚ö†Ô∏è  Rate limit! Bekleniyor {wait_time}s...")
                time.sleep(wait_time)
                
                if attempt == self.max_retries - 1:
                    return {
                        'success': False,
                        'content': None,
                        'error': f"Rate limit exceeded after {self.max_retries} attempts",
                        'usage': None
                    }
                    
            except APIError as e:
                # API error (503, 500, etc.)
                if attempt < self.max_retries - 1:
                    print(f"‚ö†Ô∏è  API error, tekrar deneniyor... ({attempt + 1}/{self.max_retries})")
                    time.sleep(self.retry_delay)
                else:
                    return {
                        'success': False,
                        'content': None,
                        'error': f"API error: {str(e)}",
                        'usage': None
                    }
                    
            except OpenAIError as e:
                # Diƒüer OpenAI hatalarƒ±
                return {
                    'success': False,
                    'content': None,
                    'error': f"OpenAI error: {str(e)}",
                    'usage': None
                }
                
            except Exception as e:
                # Beklenmeyen hatalar
                return {
                    'success': False,
                    'content': None,
                    'error': f"Unexpected error: {str(e)}",
                    'usage': None
                }
        
        return {
            'success': False,
            'content': None,
            'error': 'Max retries exceeded',
            'usage': None
        }

# Kullanƒ±m
if __name__ == "__main__":
    api = AdvancedChatGPT(max_retries=3)
    
    result = api.chat_with_retry(
        "Python ile API kullanƒ±mƒ± nasƒ±l yapƒ±lƒ±r?",
        temperature=0.7,
        max_tokens=500
    )
    
    if result['success']:
        print(f"‚úÖ Ba≈üarƒ±lƒ±!")
        print(f"Yanƒ±t: {result['content']}")
        print(f"Token kullanƒ±mƒ±: {result['usage']}")
    else:
        print(f"‚ùå Hata: {result['error']}")
```

---

### 2. Function Calling (Tools)

**`function_calling_example.py`:**
```python
#!/usr/bin/env python3
"""
OpenAI Function Calling √∂rneƒüi
"""

import os
import json
from openai import OpenAI
from dotenv import load_dotenv

load_dotenv()
client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))

# Kullanƒ±labilir fonksiyonlar
def get_weather(location: str, unit: str = "celsius") -> dict:
    """Hava durumu bilgisi al (√∂rnek)"""
    # Ger√ßek uygulamada weather API √ßaƒüƒ±rƒ±rsƒ±nƒ±z
    return {
        "location": location,
        "temperature": 22,
        "unit": unit,
        "condition": "G√ºne≈üli"
    }

def calculate(operation: str, a: float, b: float) -> float:
    """Matematiksel i≈ülem yap"""
    if operation == "add":
        return a + b
    elif operation == "subtract":
        return a - b
    elif operation == "multiply":
        return a * b
    elif operation == "divide":
        return a / b if b != 0 else "Error: Division by zero"

# Function definitions (OpenAI i√ßin)
functions = [
    {
        "name": "get_weather",
        "description": "Belirtilen lokasyon i√ßin hava durumu bilgisi al",
        "parameters": {
            "type": "object",
            "properties": {
                "location": {
                    "type": "string",
                    "description": "≈ûehir adƒ±, √∂rn: ƒ∞stanbul, Ankara"
                },
                "unit": {
                    "type": "string",
                    "enum": ["celsius", "fahrenheit"],
                    "description": "Sƒ±caklƒ±k birimi"
                }
            },
            "required": ["location"]
        }
    },
    {
        "name": "calculate",
        "description": "ƒ∞ki sayƒ± arasƒ±nda matematiksel i≈ülem yap",
        "parameters": {
            "type": "object",
            "properties": {
                "operation": {
                    "type": "string",
                    "enum": ["add", "subtract", "multiply", "divide"],
                    "description": "Yapƒ±lacak i≈ülem"
                },
                "a": {"type": "number", "description": "ƒ∞lk sayƒ±"},
                "b": {"type": "number", "description": "ƒ∞kinci sayƒ±"}
            },
            "required": ["operation", "a", "b"]
        }
    }
]

def chat_with_functions(prompt: str):
    """Function calling ile chat"""
    
    messages = [{"role": "user", "content": prompt}]
    
    # ƒ∞lk API √ßaƒürƒ±sƒ±
    response = client.chat.completions.create(
        model="gpt-4-turbo-preview",
        messages=messages,
        functions=functions,
        function_call="auto"
    )
    
    message = response.choices[0].message
    
    # Function call olup olmadƒ±ƒüƒ±nƒ± kontrol et
    if message.function_call:
        function_name = message.function_call.name
        function_args = json.loads(message.function_call.arguments)
        
        print(f"üîß Function √ßaƒürƒ±lƒ±yor: {function_name}")
        print(f"   Arguments: {function_args}")
        
        # ƒ∞lgili fonksiyonu √ßaƒüƒ±r
        if function_name == "get_weather":
            function_response = get_weather(**function_args)
        elif function_name == "calculate":
            function_response = calculate(**function_args)
        else:
            function_response = "Unknown function"
        
        print(f"   Sonu√ß: {function_response}\n")
        
        # Function sonucunu mesajlara ekle
        messages.append(message)
        messages.append({
            "role": "function",
            "name": function_name,
            "content": json.dumps(function_response)
        })
        
        # ƒ∞kinci API √ßaƒürƒ±sƒ± (sonucu formatla)
        second_response = client.chat.completions.create(
            model="gpt-4-turbo-preview",
            messages=messages
        )
        
        return second_response.choices[0].message.content
    
    else:
        # Function call yok, direkt yanƒ±t
        return message.content

# Kullanƒ±m
if __name__ == "__main__":
    # Hava durumu sorusu
    print("=== Test 1: Hava Durumu ===")
    result1 = chat_with_functions("ƒ∞stanbul'da hava nasƒ±l?")
    print(f"Yanƒ±t: {result1}\n")
    
    # Matematik sorusu
    print("=== Test 2: Hesaplama ===")
    result2 = chat_with_functions("25 ile 17'yi topla")
    print(f"Yanƒ±t: {result2}")
```

---

### 3. Async/Await ile Parallel Requests

**`async_example.py`:**
```python
#!/usr/bin/env python3
"""
Async/Await ile paralel API √ßaƒürƒ±larƒ±
"""

import os
import asyncio
from openai import AsyncOpenAI
from dotenv import load_dotenv
from typing import List

load_dotenv()

# Async client
client = AsyncOpenAI(api_key=os.getenv('OPENAI_API_KEY'))

async def async_chat(prompt: str, model: str = "gpt-3.5-turbo") -> str:
    """Async chat completion"""
    try:
        response = await client.chat.completions.create(
            model=model,
            messages=[{"role": "user", "content": prompt}],
            temperature=0.7
        )
        return response.choices[0].message.content
    except Exception as e:
        return f"Error: {str(e)}"

async def batch_chat(prompts: List[str]) -> List[str]:
    """Birden fazla prompt'u paralel olarak i≈üle"""
    tasks = [async_chat(prompt) for prompt in prompts]
    results = await asyncio.gather(*tasks)
    return results

# Kullanƒ±m
if __name__ == "__main__":
    prompts = [
        "Python nedir?",
        "JavaScript nedir?",
        "TypeScript nedir?",
        "Go nedir?",
        "Rust nedir?"
    ]
    
    print("üöÄ 5 soru paralel olarak g√∂nderiliyor...\n")
    
    import time
    start = time.time()
    
    # Async olarak √ßalƒ±≈ütƒ±r
    results = asyncio.run(batch_chat(prompts))
    
    end = time.time()
    
    # Sonu√ßlarƒ± g√∂ster
    for i, (prompt, result) in enumerate(zip(prompts, results), 1):
        print(f"Soru {i}: {prompt}")
        print(f"Yanƒ±t: {result[:100]}...\n")
    
    print(f"‚è±Ô∏è  Toplam s√ºre: {end - start:.2f} saniye")
    print(f"   (Sƒ±ralƒ± yapƒ±lsaydƒ±: ~{len(prompts) * 2:.0f} saniye)")
```

---

## ‚úÖ Best Practices

### 1. G√ºvenlik

```python
# ‚úÖ ƒ∞Yƒ∞: Environment variables
api_key = os.getenv('OPENAI_API_KEY')

# ‚ùå K√ñT√ú: Hardcoded API key
api_key = "sk-abc123..."  # Asla yapma!

# ‚úÖ ƒ∞Yƒ∞: .gitignore'a ekle
# .env
# *.pyc
# __pycache__/
```

### 2. Error Handling

```python
# ‚úÖ ƒ∞Yƒ∞: Spesifik exception'larƒ± yakala
try:
    response = client.chat.completions.create(...)
except RateLimitError:
    # Rate limit √∂zel i≈ülemi
    handle_rate_limit()
except APIError as e:
    # API hatasƒ±
    log_error(e)
except OpenAIError as e:
    # Genel OpenAI hatasƒ±
    notify_user(str(e))

# ‚ùå K√ñT√ú: Genel exception
try:
    response = client.chat.completions.create(...)
except Exception as e:
    pass  # Sessizce ge√ß
```

### 3. Token Management

```python
# Token kullanƒ±mƒ±nƒ± takip et
def chat_with_token_tracking(prompt: str):
    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[{"role": "user", "content": prompt}]
    )
    
    usage = response.usage
    cost = calculate_cost(
        model="gpt-3.5-turbo",
        prompt_tokens=usage.prompt_tokens,
        completion_tokens=usage.completion_tokens
    )
    
    print(f"üìä Token kullanƒ±mƒ±:")
    print(f"   Prompt: {usage.prompt_tokens}")
    print(f"   Completion: {usage.completion_tokens}")
    print(f"   Total: {usage.total_tokens}")
    print(f"   üí∞ Maliyet: ${cost:.4f}")
    
    return response.choices[0].message.content

def calculate_cost(model: str, prompt_tokens: int, completion_tokens: int) -> float:
    """Token maliyetini hesapla"""
    # GPT-3.5-turbo fiyatlarƒ± (√∂rnek)
    costs = {
        "gpt-3.5-turbo": {
            "prompt": 0.0005 / 1000,      # $0.0005 per 1K tokens
            "completion": 0.0015 / 1000    # $0.0015 per 1K tokens
        },
        "gpt-4-turbo-preview": {
            "prompt": 0.01 / 1000,
            "completion": 0.03 / 1000
        }
    }
    
    model_costs = costs.get(model, costs["gpt-3.5-turbo"])
    total = (prompt_tokens * model_costs["prompt"]) + \
            (completion_tokens * model_costs["completion"])
    
    return total
```

### 4. Logging

```python
import logging
from datetime import datetime

# Logging setup
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('chatgpt_api.log'),
        logging.StreamHandler()
    ]
)

logger = logging.getLogger(__name__)

def chat_with_logging(prompt: str):
    """Logging ile chat"""
    logger.info(f"Chat request: {prompt[:50]}...")
    
    try:
        start_time = datetime.now()
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "user", "content": prompt}]
        )
        
        duration = (datetime.now() - start_time).total_seconds()
        
        logger.info(f"Chat response received in {duration:.2f}s")
        logger.debug(f"Token usage: {response.usage.total_tokens}")
        
        return response.choices[0].message.content
        
    except Exception as e:
        logger.error(f"Chat error: {str(e)}", exc_info=True)
        raise
```

---

## üêõ Troubleshooting

### Sƒ±k Kar≈üƒ±la≈üƒ±lan Hatalar

#### 1. Authentication Error
```python
# Hata: openai.AuthenticationError: Invalid API key

# √á√∂z√ºm:
# 1. API key'i kontrol et
print(os.getenv('OPENAI_API_KEY'))  # None olmamalƒ±

# 2. .env dosyasƒ±nƒ±n y√ºklendiƒüini kontrol et
from dotenv import load_dotenv
load_dotenv()

# 3. API key formatƒ±nƒ± kontrol et
# Doƒüru format: sk-... (48+ karakter)
```

#### 2. Rate Limit Error
```python
# Hata: openai.RateLimitError: Rate limit exceeded

# √á√∂z√ºm: Retry logic ekle
import time

for attempt in range(3):
    try:
        response = client.chat.completions.create(...)
        break
    except RateLimitError:
        if attempt < 2:
            wait_time = (2 ** attempt)  # 1s, 2s, 4s
            print(f"Rate limit! {wait_time}s bekleniyor...")
            time.sleep(wait_time)
        else:
            raise
```

#### 3. Model Not Found Error
```python
# Hata: Model 'gpt-4' not found

# √á√∂z√ºm: Model eri≈üiminizi kontrol edin
# GPT-4 i√ßin √∂zel eri≈üim gerekir
# Alternatif: gpt-3.5-turbo veya gpt-4-turbo-preview
```

#### 4. Connection Error
```python
# Hata: Connection timeout

# √á√∂z√ºm: Timeout ayarƒ±
client = OpenAI(
    api_key=os.getenv('OPENAI_API_KEY'),
    timeout=30.0,  # 30 saniye timeout
    max_retries=2
)
```

---

## üìö Ek Kaynaklar

- **OpenAI Docs**: https://platform.openai.com/docs
- **Python Client**: https://github.com/openai/openai-python
- **Best Practices**: https://platform.openai.com/docs/guides/production-best-practices
- **Rate Limits**: https://platform.openai.com/docs/guides/rate-limits
- **Pricing**: https://openai.com/pricing

---

## üéì √ñrnek Projeler

Tam √ßalƒ±≈üan √∂rnek projeler i√ßin dok√ºmantasyon dosyalarƒ±na bakƒ±n:
- `examples/basic_chatbot.py` - Basit chatbot
- `examples/advanced_assistant.py` - Geli≈ümi≈ü asistan
- `examples/function_calling_app.py` - Function calling √∂rneƒüi

---

**Version**: 1.0.0  
**Last Updated**: 2025-10-05  
**Status**: ‚úÖ Production Ready
