# ğŸ†“ Ãœcretsiz AI API'leri - KapsamlÄ± Rehber

## ğŸ“‹ Ä°Ã§indekiler
1. [Genel KarÅŸÄ±laÅŸtÄ±rma](#genel-karÅŸÄ±laÅŸtÄ±rma)
2. [Google Gemini (ÃœCRETSÄ°Z)](#google-gemini)
3. [Hugging Face (ÃœCRETSÄ°Z)](#hugging-face)
4. [Groq (ÃœCRETSÄ°Z)](#groq)
5. [Cohere (ÃœCRETSÄ°Z)](#cohere)
6. [OpenAI (Ãœcretli - Credit ile baÅŸlangÄ±Ã§)](#openai)
7. [Anthropic Claude (Ãœcretli - Credit ile baÅŸlangÄ±Ã§)](#anthropic-claude)
8. [Meta Llama (AÃ§Ä±k Kaynak - Kendi Sunucunuzda)](#meta-llama)
9. [Mistral (KÄ±smen Ãœcretsiz)](#mistral)
10. [Unified KullanÄ±m](#unified-kullanÄ±m)

---

## ğŸ“Š Genel KarÅŸÄ±laÅŸtÄ±rma

| AI Servisi | Ãœcretsiz Tier | Limit | API Key | Avantajlar |
|------------|---------------|-------|---------|------------|
| **ğŸŒŸ Gemini** | âœ… TAM ÃœCRETSÄ°Z | 60 req/min | Gerekli | En cÃ¶mert, vision |
| **ğŸ¤— Hugging Face** | âœ… TAM ÃœCRETSÄ°Z | Rate limit var | Gerekli | Binlerce model |
| **âš¡ Groq** | âœ… TAM ÃœCRETSÄ°Z | 30 req/min | Gerekli | Ultra hÄ±zlÄ± |
| **ğŸ”® Cohere** | âœ… Deneme | 5K/ay ilk ay | Gerekli | Trial period |
| **ğŸ¤– OpenAI** | âŒ $5 credit | - | Gerekli | En popÃ¼ler |
| **ğŸ’¬ Claude** | âŒ $5 credit | - | Gerekli | En iyi reasoning |
| **ğŸ¦™ Llama** | âœ… AÃ§Ä±k kaynak | SÄ±nÄ±rsÄ±z | - | Kendi sunucu |
| **ğŸŒªï¸ Mistral** | âš ï¸ KÄ±smen | - | Gerekli | BazÄ± modeller |

### ğŸ† En Ä°yi Ãœcretsiz SeÃ§enekler

#### 1. **Google Gemini** ğŸ¥‡
- âœ… **Tamamen Ã¼cretsiz**
- âœ… 60 requests/minute
- âœ… 1,500 requests/day
- âœ… Vision support (resim analizi)
- âœ… Uzun context (30K-1M tokens)
- ğŸ¯ **Ã–nerilen baÅŸlangÄ±Ã§!**

#### 2. **Groq** ğŸ¥ˆ
- âœ… Tamamen Ã¼cretsiz
- âœ… Ultra hÄ±zlÄ± inference
- âœ… Llama 3, Mixtral modelleri
- âœ… 30 requests/minute
- ğŸ¯ **En hÄ±zlÄ± yanÄ±t!**

#### 3. **Hugging Face** ğŸ¥‰
- âœ… Binlerce Ã¼cretsiz model
- âœ… Ã‡eÅŸitlilik
- âœ… Community modelleri
- âš ï¸ Rate limit var
- ğŸ¯ **En fazla seÃ§enek!**

---

## ğŸŒŸ Google Gemini (TAM ÃœCRETSÄ°Z)

### Ã–zellikler
- âœ… **Tamamen Ã¼cretsiz** (kalÄ±cÄ±)
- âœ… 60 requests/minute
- âœ… 1,500 requests/day
- âœ… Vision support
- âœ… Context: 30K-1M tokens

### HÄ±zlÄ± Kurulum

```bash
# 1. API Key al
# https://makersuite.google.com/app/apikey

# 2. Kur
pip install google-generativeai python-dotenv

# 3. .env oluÅŸtur
echo "GEMINI_API_KEY=AIzaYour..." > .env
```

### KullanÄ±m

```python
import google.generativeai as genai
import os
from dotenv import load_dotenv

load_dotenv()
genai.configure(api_key=os.getenv('GEMINI_API_KEY'))

# Model
model = genai.GenerativeModel('gemini-pro')

# Generate
response = model.generate_content("Python nedir?")
print(response.text)
```

**Detaylar**: `GEMINI_PYTHON_SETUP.md`

---

## ğŸ¤— Hugging Face (TAM ÃœCRETSÄ°Z)

### Ã–zellikler
- âœ… **Tamamen Ã¼cretsiz**
- âœ… Binlerce model
- âœ… Community modelleri
- âœ… Inference API
- âš ï¸ Rate limit var (deÄŸiÅŸken)

### HÄ±zlÄ± Kurulum

```bash
# 1. API Key al
# https://huggingface.co/settings/tokens

# 2. Kur
pip install huggingface-hub requests

# 3. .env oluÅŸtur
echo "HUGGINGFACE_API_KEY=hf_..." > .env
```

### KullanÄ±m

```python
import os
import requests
from dotenv import load_dotenv

load_dotenv()

API_URL = "https://api-inference.huggingface.co/models/gpt2"
headers = {"Authorization": f"Bearer {os.getenv('HUGGINGFACE_API_KEY')}"}

def query(payload):
    response = requests.post(API_URL, headers=headers, json=payload)
    return response.json()

# Generate
output = query({
    "inputs": "Python nedir?",
})
print(output)
```

### PopÃ¼ler Ãœcretsiz Modeller

```python
# Text Generation
"gpt2"
"distilgpt2"
"facebook/opt-350m"
"EleutherAI/gpt-neo-125m"

# Translation
"Helsinki-NLP/opus-mt-en-tr"
"facebook/mbart-large-50-many-to-many-mmt"

# Sentiment Analysis
"distilbert-base-uncased-finetuned-sst-2-english"
"cardiffnlp/twitter-roberta-base-sentiment"

# Summarization
"facebook/bart-large-cnn"
"t5-small"
```

---

## âš¡ Groq (TAM ÃœCRETSÄ°Z)

### Ã–zellikler
- âœ… **Tamamen Ã¼cretsiz**
- âœ… Ultra hÄ±zlÄ± (Ã¶zel hardware)
- âœ… Llama 3, Mixtral modelleri
- âœ… 30 requests/minute
- âœ… 14,400 requests/day

### HÄ±zlÄ± Kurulum

```bash
# 1. API Key al
# https://console.groq.com/keys

# 2. Kur
pip install groq

# 3. .env oluÅŸtur
echo "GROQ_API_KEY=gsk_..." > .env
```

### KullanÄ±m

```python
from groq import Groq
import os
from dotenv import load_dotenv

load_dotenv()

client = Groq(api_key=os.getenv("GROQ_API_KEY"))

chat_completion = client.chat.completions.create(
    messages=[
        {
            "role": "user",
            "content": "Python nedir?",
        }
    ],
    model="llama3-70b-8192",  # veya mixtral-8x7b-32768
)

print(chat_completion.choices[0].message.content)
```

### Mevcut Modeller

```python
# Llama 3
"llama3-70b-8192"   # En gÃ¼Ã§lÃ¼
"llama3-8b-8192"    # HÄ±zlÄ±

# Mixtral
"mixtral-8x7b-32768"

# Gemma
"gemma-7b-it"
```

---

## ğŸ”® Cohere (Deneme Ãœcretsiz)

### Ã–zellikler
- âœ… Ä°lk ay Ã¼cretsiz (5K requests)
- âœ… Production trial
- âœ… Ã–zel embedding models
- âš ï¸ Sonra Ã¼cretli

### HÄ±zlÄ± Kurulum

```bash
# 1. API Key al
# https://dashboard.cohere.com/api-keys

# 2. Kur
pip install cohere

# 3. .env oluÅŸtur
echo "COHERE_API_KEY=..." > .env
```

### KullanÄ±m

```python
import cohere
import os
from dotenv import load_dotenv

load_dotenv()

co = cohere.Client(os.getenv('COHERE_API_KEY'))

response = co.generate(
    prompt="Python nedir?",
    max_tokens=200,
    temperature=0.7
)

print(response.generations[0].text)
```

---

## ğŸ¤– OpenAI (Ãœcretli - $5 Credit ile BaÅŸlangÄ±Ã§)

### Ã–zellikler
- âŒ Ãœcretsiz tier yok
- âœ… Yeni hesaplara $5 credit
- âœ… En popÃ¼ler
- âœ… GPT-4, GPT-3.5-turbo
- âš ï¸ Credit bitince Ã¼cretli

### Fiyatlar

```
GPT-3.5-turbo:  $0.0005/1K input,  $0.0015/1K output
GPT-4-turbo:    $0.01/1K input,    $0.03/1K output
GPT-4o:         $0.005/1K input,   $0.015/1K output
```

### $5 Credit ile Ne Kadar?

```
GPT-3.5-turbo: ~2,500 requests (ortalama)
GPT-4-turbo:   ~200 requests (ortalama)
```

### KullanÄ±m

```python
from openai import OpenAI
import os

client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))

response = client.chat.completions.create(
    model="gpt-3.5-turbo",
    messages=[{"role": "user", "content": "Python nedir?"}]
)

print(response.choices[0].message.content)
```

**Detaylar**: `PYTHON_OPENAI_SETUP.md`

---

## ğŸ’¬ Anthropic Claude (Ãœcretli - $5 Credit ile BaÅŸlangÄ±Ã§)

### Ã–zellikler
- âŒ Ãœcretsiz tier yok
- âœ… Yeni hesaplara $5 credit
- âœ… En iyi reasoning
- âœ… 200K context window
- âš ï¸ Credit bitince Ã¼cretli

### Fiyatlar

```
Claude 3 Haiku:   $0.25/1M input,  $1.25/1M output
Claude 3 Sonnet:  $3/1M input,     $15/1M output
Claude 3 Opus:    $15/1M input,    $75/1M output
```

### KullanÄ±m

```python
import anthropic
import os

client = anthropic.Anthropic(
    api_key=os.getenv('ANTHROPIC_API_KEY')
)

message = client.messages.create(
    model="claude-3-sonnet-20240229",
    max_tokens=1024,
    messages=[
        {"role": "user", "content": "Python nedir?"}
    ]
)

print(message.content[0].text)
```

---

## ğŸ¦™ Meta Llama (AÃ§Ä±k Kaynak - Kendi Sunucunuzda)

### Ã–zellikler
- âœ… **Tamamen Ã¼cretsiz** (aÃ§Ä±k kaynak)
- âœ… SÄ±nÄ±rsÄ±z kullanÄ±m
- âœ… Llama 3, 3.1, 3.2
- âš ï¸ Kendi sunucunuzda Ã§alÄ±ÅŸtÄ±rmanÄ±z gerekir

### Option 1: Ollama (Ã–nerilen - En Kolay)

```bash
# 1. Ollama kur
# Linux/macOS:
curl -fsSL https://ollama.com/install.sh | sh

# Windows:
# https://ollama.com/download/windows

# 2. Model indir ve Ã§alÄ±ÅŸtÄ±r
ollama run llama3

# 3. API kullan (localhost:11434)
```

**Python ile:**

```python
import requests

response = requests.post('http://localhost:11434/api/generate', 
    json={
        "model": "llama3",
        "prompt": "Python nedir?",
        "stream": False
    }
)

print(response.json()['response'])
```

### Option 2: Transformers (Hugging Face)

```bash
pip install transformers torch
```

```python
from transformers import AutoTokenizer, AutoModelForCausalLM

model_name = "meta-llama/Llama-2-7b-chat-hf"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForCausalLM.from_pretrained(model_name)

# Generate
inputs = tokenizer("Python nedir?", return_tensors="pt")
outputs = model.generate(**inputs, max_length=100)
print(tokenizer.decode(outputs[0]))
```

âš ï¸ **Not**: GPU gerektirir (bÃ¼yÃ¼k modeller iÃ§in)

### Llama Modelleri

```
llama3:8b     - 8B parametreli (4-8GB RAM)
llama3:70b    - 70B parametreli (40+ GB RAM)
llama3.1      - En yeni versiyon
llama3.2      - Vision support
```

---

## ğŸŒªï¸ Mistral (KÄ±smen Ãœcretsiz)

### Ã–zellikler
- âš ï¸ BazÄ± modeller Ã¼cretsiz
- âœ… Mistral 7B aÃ§Ä±k kaynak
- âš ï¸ API Ã§oÄŸunlukla Ã¼cretli

### AÃ§Ä±k Kaynak Modeller

```bash
# Ollama ile
ollama run mistral

# Hugging Face ile
pip install transformers
```

```python
from transformers import AutoTokenizer, AutoModelForCausalLM

model = AutoModelForCausalLM.from_pretrained("mistralai/Mistral-7B-v0.1")
tokenizer = AutoTokenizer.from_pretrained("mistralai/Mistral-7B-v0.1")
```

---

## ğŸ¯ Unified KullanÄ±m (TÃ¼m API'leri Tek ArayÃ¼zle)

### Unified AI Client OluÅŸturma

**`unified_ai.py`:**

```python
import os
from typing import Optional, Dict, Any
from dotenv import load_dotenv

# AI Libraries
import google.generativeai as genai
from openai import OpenAI
import anthropic
from groq import Groq
import requests

load_dotenv()

class UnifiedAI:
    """TÃ¼m AI API'lerini tek arayÃ¼zle kullan"""
    
    def __init__(self):
        # API Keys
        self.gemini_key = os.getenv('GEMINI_API_KEY')
        self.openai_key = os.getenv('OPENAI_API_KEY')
        self.anthropic_key = os.getenv('ANTHROPIC_API_KEY')
        self.groq_key = os.getenv('GROQ_API_KEY')
        self.hf_key = os.getenv('HUGGINGFACE_API_KEY')
        
        # Initialize clients
        if self.gemini_key:
            genai.configure(api_key=self.gemini_key)
            self.gemini = genai.GenerativeModel('gemini-pro')
        
        if self.openai_key:
            self.openai = OpenAI(api_key=self.openai_key)
        
        if self.anthropic_key:
            self.claude = anthropic.Anthropic(api_key=self.anthropic_key)
        
        if self.groq_key:
            self.groq = Groq(api_key=self.groq_key)
    
    def generate(
        self, 
        prompt: str, 
        provider: str = "gemini",
        model: Optional[str] = None,
        **kwargs
    ) -> str:
        """
        Unified generate method
        
        Args:
            prompt: User prompt
            provider: 'gemini', 'openai', 'claude', 'groq', 'huggingface'
            model: Specific model (optional)
            **kwargs: Additional parameters
            
        Returns:
            Generated text
        """
        
        if provider == "gemini":
            return self._generate_gemini(prompt, **kwargs)
        elif provider == "openai":
            return self._generate_openai(prompt, model or "gpt-3.5-turbo", **kwargs)
        elif provider == "claude":
            return self._generate_claude(prompt, model or "claude-3-sonnet-20240229", **kwargs)
        elif provider == "groq":
            return self._generate_groq(prompt, model or "llama3-70b-8192", **kwargs)
        elif provider == "huggingface":
            return self._generate_huggingface(prompt, model or "gpt2", **kwargs)
        else:
            raise ValueError(f"Unknown provider: {provider}")
    
    def _generate_gemini(self, prompt: str, **kwargs) -> str:
        """Gemini generation"""
        response = self.gemini.generate_content(prompt)
        return response.text
    
    def _generate_openai(self, prompt: str, model: str, **kwargs) -> str:
        """OpenAI generation"""
        response = self.openai.chat.completions.create(
            model=model,
            messages=[{"role": "user", "content": prompt}],
            **kwargs
        )
        return response.choices[0].message.content
    
    def _generate_claude(self, prompt: str, model: str, **kwargs) -> str:
        """Claude generation"""
        message = self.claude.messages.create(
            model=model,
            max_tokens=1024,
            messages=[{"role": "user", "content": prompt}],
            **kwargs
        )
        return message.content[0].text
    
    def _generate_groq(self, prompt: str, model: str, **kwargs) -> str:
        """Groq generation"""
        chat_completion = self.groq.chat.completions.create(
            messages=[{"role": "user", "content": prompt}],
            model=model,
            **kwargs
        )
        return chat_completion.choices[0].message.content
    
    def _generate_huggingface(self, prompt: str, model: str, **kwargs) -> str:
        """Hugging Face generation"""
        API_URL = f"https://api-inference.huggingface.co/models/{model}"
        headers = {"Authorization": f"Bearer {self.hf_key}"}
        
        response = requests.post(
            API_URL, 
            headers=headers, 
            json={"inputs": prompt, **kwargs}
        )
        
        result = response.json()
        if isinstance(result, list) and len(result) > 0:
            return result[0].get('generated_text', str(result))
        return str(result)

# KullanÄ±m
if __name__ == "__main__":
    ai = UnifiedAI()
    
    prompt = "Python nedir? KÄ±saca aÃ§Ä±kla."
    
    # Gemini (Ã¼cretsiz)
    print("ğŸŒŸ Gemini:", ai.generate(prompt, provider="gemini"))
    
    # Groq (Ã¼cretsiz)
    print("âš¡ Groq:", ai.generate(prompt, provider="groq"))
    
    # OpenAI (Ã¼cretli)
    # print("ğŸ¤– OpenAI:", ai.generate(prompt, provider="openai"))
    
    # Claude (Ã¼cretli)
    # print("ğŸ’¬ Claude:", ai.generate(prompt, provider="claude"))
```

---

## ğŸ’° Maliyet KarÅŸÄ±laÅŸtÄ±rmasÄ±

### Ãœcretsiz SeÃ§enekler (SÄ±nÄ±rsÄ±za YakÄ±n)

| Servis | AylÄ±k KullanÄ±m | Limit | Maliyet |
|--------|----------------|-------|---------|
| **Gemini** | 1,500 req/gÃ¼n | 45K/ay | $0 |
| **Groq** | 14,400 req/gÃ¼n | 432K/ay | $0 |
| **Hugging Face** | DeÄŸiÅŸken | Rate limit | $0 |
| **Llama (Ollama)** | SÄ±nÄ±rsÄ±z | - | $0 (elektrik) |

### Ãœcretli SeÃ§enekler (1M token iÃ§in)

| Servis | Input | Output | Toplam |
|--------|-------|--------|--------|
| **OpenAI GPT-3.5** | $0.50 | $1.50 | $2.00 |
| **OpenAI GPT-4** | $10.00 | $30.00 | $40.00 |
| **Claude Haiku** | $0.25 | $1.25 | $1.50 |
| **Claude Sonnet** | $3.00 | $15.00 | $18.00 |

---

## ğŸ¯ Hangi AI'yi SeÃ§meliyim?

### Senaryolara GÃ¶re Ã–neriler:

#### ğŸ“ Ã–ÄŸrenme / Deneme
**Ã–nerilen**: Gemini + Groq
- âœ… Tamamen Ã¼cretsiz
- âœ… CÃ¶mert limitler
- âœ… HÄ±zlÄ± yanÄ±tlar

#### ğŸ’¼ KÃ¼Ã§Ã¼k Proje / Startup
**Ã–nerilen**: Gemini (ana) + Ollama (backup)
- âœ… Ãœcretsiz baÅŸlangÄ±Ã§
- âœ… Ã–lÃ§eklenebilir
- âœ… Maliyet kontrolÃ¼

#### ğŸ¢ Production / Kurumsal
**Ã–nerilen**: OpenAI GPT-4 / Claude 3
- âœ… En iyi kalite
- âœ… GÃ¼venilirlik
- âœ… Support
- âš ï¸ Ãœcretli

#### ğŸ”¬ AraÅŸtÄ±rma / Deney
**Ã–nerilen**: Hugging Face + Llama
- âœ… Binlerce model
- âœ… AÃ§Ä±k kaynak
- âœ… Ã–zelleÅŸtirilebilir

---

## ğŸ“š DetaylÄ± DokÃ¼mantasyon

- **Gemini**: `GEMINI_PYTHON_SETUP.md`
- **OpenAI**: `PYTHON_OPENAI_SETUP.md`
- **TÃ¼m API'ler**: Bu dosya

---

## ğŸ”— Kaynaklar

### API Keys:
- **Gemini**: https://makersuite.google.com/app/apikey
- **OpenAI**: https://platform.openai.com/api-keys
- **Claude**: https://console.anthropic.com/
- **Groq**: https://console.groq.com/keys
- **Hugging Face**: https://huggingface.co/settings/tokens
- **Cohere**: https://dashboard.cohere.com/api-keys

### DokÃ¼mantasyon:
- **Gemini**: https://ai.google.dev/docs
- **OpenAI**: https://platform.openai.com/docs
- **Claude**: https://docs.anthropic.com/
- **Groq**: https://console.groq.com/docs
- **Hugging Face**: https://huggingface.co/docs
- **Ollama**: https://ollama.com/

---

**Version**: 1.0.0  
**Last Updated**: 2025-10-05  
**Status**: âœ… Production Ready
